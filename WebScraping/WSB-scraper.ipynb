{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "painted-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import urllib.request\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "recent-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromDate(start_date):\n",
    "    day_to_be_scraped = start_date\n",
    "    today = datetime.today()\n",
    "    days_without_data = []\n",
    "    \n",
    "    bx_url = 'ftp://ftp.nasdaqtrader.com/files/shortsaledata/daily/bx/NQBXshvol'\n",
    "    psx_url = 'ftp://ftp.nasdaqtrader.com/files/shortsaledata/daily/psx/NPSXshvol'\n",
    "    finra_url = 'http://regsho.finra.org/CNMSshvol'\n",
    "    \n",
    "    if (not os.path.isdir('B')):\n",
    "        os.mkdir('B')\n",
    "    if (not os.path.isdir('P')):\n",
    "        os.mkdir('P')\n",
    "    if (not os.path.isdir('F')):\n",
    "        os.mkdir('F')\n",
    "\n",
    "    while (day_to_be_scraped <= today):\n",
    "        filename = (day_to_be_scraped).strftime('%Y%m%d') + '.txt'\n",
    "        try:\n",
    "\n",
    "            # must be done with requests. 403 Forbidden otherwise\n",
    "            # TODO: clean the files that are failed http requests\n",
    "            finra_query = requests.get(finra_url+filename)\n",
    "            with open('F/'+filename, 'wb') as outfile:\n",
    "                outfile.write(finra_query.content)\n",
    "\n",
    "\n",
    "            with closing(request.urlopen(bx_url+filename)) as bx_query:\n",
    "                with open('B/'+filename, 'wb') as f:\n",
    "                    shutil.copyfileobj(bx_query, f)\n",
    "\n",
    "            with closing(request.urlopen(psx_url+filename)) as psx_query:\n",
    "                with open('P/'+filename, 'wb') as f:\n",
    "                    shutil.copyfileobj(psx_query, f)\n",
    "                \n",
    "\n",
    "        except:\n",
    "            print('no data for '+ filename)\n",
    "            \n",
    "            #kinda hacky\n",
    "            days_without_data +=[filename]\n",
    "            \n",
    "\n",
    "        day_to_be_scraped += timedelta(days=1)\n",
    "        \n",
    "    return days_without_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "suited-comedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for 20210130.txt\n",
      "no data for 20210131.txt\n",
      "no data for 20210206.txt\n",
      "no data for 20210207.txt\n",
      "no data for 20210213.txt\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today()\n",
    "day_to_be_scraped = today - timedelta(days=15)\n",
    "\n",
    "files_to_be_removed = getDataFromDate(day_to_be_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "answering-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean finra files that have no data\n",
    "for finra_file in files_to_be_removed:\n",
    "    os.remove('F/'+finra_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-enlargement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install python-crontab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
